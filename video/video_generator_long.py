from openai import OpenAI
import os
import time

OUTPUT_BG_VIDEO = "output/long_video.mp4"

CI_VALUE = os.environ.get("CI", "").lower()
IS_CI = CI_VALUE in ("1", "true", "yes")

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def generate_bg_video(prompt: str):
    if IS_CI:
        print("CI í™˜ê²½: Sora ë¹„ë””ì˜¤ ìƒì„± ìŠ¤í‚µ (ë”ë¯¸ ì˜ìƒ ì‚¬ìš©)", flush=True)

        # ë”ë¯¸ 16:9 ì˜ìƒ ìƒì„±
        os.system(
            "ffmpeg -y -f lavfi -i color=c=black:s=1280x720:r=30 -t 5 output/long_video.mp4"
        )
        return OUTPUT_BG_VIDEO

    print("ğŸ¥ Sora ë°°ê²½ ì˜ìƒ ìƒì„± ì‹œì‘", flush=True)

    job = client.videos.create(
        model="sora-2",
        prompt=prompt,
        size="720x1280",
        seconds=12
    )

    # ì•ˆì „í•œ í´ë§ (íƒ€ì„ì•„ì›ƒ í¬í•¨)
    for _ in range(60):  # ìµœëŒ€ 60ì´ˆ
        job = client.videos.retrieve(job.id)
        print(f"â³ Sora status: {job.status}", flush=True)

        if job.status == "succeeded":
            break
        if job.status == "failed":
            raise RuntimeError("Sora ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")

        time.sleep(2)

    if job.status != "succeeded":
        raise TimeoutError("Sora ë¹„ë””ì˜¤ ìƒì„± íƒ€ì„ì•„ì›ƒ")

    content = client.videos.download_content(job.id, variant="video")
    content.write_to_file(OUTPUT_BG_VIDEO)

    print("Sora ë°°ê²½ ì˜ìƒ ìƒì„± ì™„ë£Œ", flush=True)
    return OUTPUT_BG_VIDEO
